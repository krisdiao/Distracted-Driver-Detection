{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./Keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dependencies\n",
    "\n",
    "#general\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import pickle\n",
    "import pprint\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# sns.set_theme(style=\"dark\")\n",
    "\n",
    "#preprocessing\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Neural net\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from builtins import object\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class data_preprocess(object):\n",
    "    def __init__(self, path, transform = False):\n",
    "        super(data_preprocess, self).__init__()\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        \n",
    "    #defining function to load data for general ML\n",
    "    def load_images(self,  size= 128):\n",
    "        '''\n",
    "        Function to load images using CV2 and resized to get them ready for training\n",
    "        Arguments:\n",
    "        imgPath-- Takes in path of the image as input\n",
    "        size-- Takes in the required reduced size of image (optional)\n",
    "        Return:\n",
    "        images-- Images dataset with all the data features\n",
    "        labels-- Target labels for all the images in image dataset extracted from the directory name\n",
    "        '''\n",
    "        self.images = list()\n",
    "        self.labels = list()\n",
    "\n",
    "        for subdir in sorted(os.listdir(self.path)):\n",
    "            if subdir.strip().startswith('c'):\n",
    "                subdir_path = os.path.join(self.path, subdir)\n",
    "\n",
    "                for file in os.listdir(subdir_path):\n",
    "                    if file.endswith('jpg'):\n",
    "                        fpath = os.path.join(subdir_path,file)\n",
    "                        img = cv2.imread(fpath)\n",
    "                        img_resize = cv2.resize(img,(size,size))\n",
    "                        self.images.append(img_resize)\n",
    "                        self.labels.append(int(fpath.split('/')[-2].replace('c', '')))\n",
    "\n",
    "        return np.array(self.images), np.array(self.labels)\n",
    "    \n",
    "    \n",
    "    def keras_dataloader(self, num_classes=10, test_size = 0.2, dim = 128):\n",
    "        '''\n",
    "        Function to load images and prepare them to be used with keras models\n",
    "        Arguments:\n",
    "        num_classes-- number of target classes\n",
    "        test_size-- Takes in the required test split size\n",
    "        dim-- size of image\n",
    "        Return:\n",
    "        X and Y train test splits\n",
    "        '''\n",
    "        images, labels = self.load_images(size=dim)\n",
    "        \n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(images, labels, test_size)\n",
    "        #converting labels to categorical values\n",
    "        Y_train = tf.keras.utils.to_categorical(Y_Train, num_classes=num_classes)\n",
    "        Y_test = tf.keras.utils.to_categorical(Y_Test, num_classes=num_classes)\n",
    "        \n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "    \n",
    "    def pytorch_dataloader(self):\n",
    "        '''\n",
    "        Function to load data as per pytorch dataloader standards to be used with deep learning models\n",
    "        '''\n",
    "        #Defining image transforms\n",
    "        imgTransform =  transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((224,244)),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        data = datasets.ImageFolder(self.path, transform =imgTransform)\n",
    "        return data\n",
    "    \n",
    "    \n",
    "    \n",
    "    def split_data_train_test(self,data, test_split=0.33, batch_size = 64):\n",
    "        '''\n",
    "        Function to create train test splits for the given data\n",
    "        data-- takes input the data to be split\n",
    "        test_split-- takes input the test split ratio \n",
    "        Return train and test split datasets\n",
    "        '''\n",
    "        \n",
    "        num_samples =  len(data)\n",
    "        indices = list(range(num_samples))\n",
    "        np.random.shuffle(indices)\n",
    "        split = int(test_split*num_samples)\n",
    "\n",
    "        index_train, index_test = indices[split:], indices[:split]\n",
    "        sampler_train = SubsetRandomSampler(index_train)\n",
    "        sampler_test = SubsetRandomSampler(index_test)\n",
    "\n",
    "        trainloader = torch.utils.data.DataLoader(data,\n",
    "                       sampler=sampler_train, batch_size=batch_size)\n",
    "        testloader = torch.utils.data.DataLoader(data,\n",
    "                       sampler=sampler_test, batch_size=batch_size)\n",
    "\n",
    "        return trainloader, testloader\n",
    "\n",
    "        \n",
    "    \n",
    "    #create pickle files\n",
    "    def pickle_dump(self,transform = False ):\n",
    "        '''\n",
    "        Function to call load_images function to laod data and generate the pickle files\n",
    "        '''\n",
    "        if transform==False:\n",
    "            X, y = self.load_images()\n",
    "            pickle.dump(X, open(str('featureData'+str(self.size)+'.pkl'), 'wb'))\n",
    "            pickle.dump(y, open(str('targetData'+str(self.size)+'.pkl'),'wb'))\n",
    "    \n",
    "        elif transform==True:\n",
    "            data = self.pytorch_dataloader()\n",
    "            pickle.dump(data, open('data.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_obj = data_preprocess('./state-farm-distracted-driver-detection/imgs/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './state-farm-distracted-driver-detection/imgs/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-d87308d7ddf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdp_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-8c8b615bb693>\u001b[0m in \u001b[0;36mkeras_dataloader\u001b[0;34m(self, num_classes, test_size)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mY\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0mtest\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         '''\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-8c8b615bb693>\u001b[0m in \u001b[0;36mload_images\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0msubdir_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './state-farm-distracted-driver-detection/imgs/train'"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = dp_obj.keras_dataloader(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/prakharpatidar/Google Drive/DS/SML DS 5220/Project/python_files'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
